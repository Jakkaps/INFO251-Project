{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from core.models.nts_net import NTSModel\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import settings\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 670\n",
      "Val data size: 330\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import FGVCAircraft\n",
    "from torch.utils.data import Subset, random_split\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "Transforms\n",
    "\"\"\"\n",
    "img_mean, img_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = Compose([\n",
    "  Resize((settings.IMAGE_HEIGHT, settings.IMAGE_WIDTH), Image.BILINEAR),\n",
    "  ToTensor(),\n",
    "  Normalize(mean=img_mean, std=img_std),\n",
    "])\n",
    "\n",
    "\"\"\"\n",
    "Load dataset\n",
    "\"\"\"\n",
    "dataset = FGVCAircraft(root=\"data\", split=\"train\", download=True, transform=transform)\n",
    "\n",
    "\"\"\"\n",
    "Split data\n",
    "\"\"\"\n",
    "\n",
    "# Create a smaller subset\n",
    "num_samples = len(dataset)\n",
    "subset_size = settings.N_SAMPLES\n",
    "rand_idxs = np.random.choice(range(num_samples), subset_size)\n",
    "subset = Subset(dataset, rand_idxs)\n",
    "\n",
    "\n",
    "# Create train-val split\n",
    "val_split = int(subset_size*settings.TEST_SIZE)\n",
    "with torch.random.fork_rng(devices=[device]):\n",
    "  torch.manual_seed(settings.SEED)\n",
    "  train_data, val_data = random_split(subset, [subset_size - val_split, val_split])\n",
    "\n",
    "print(\"Train data size:\", len(train_data))\n",
    "print(\"Val data size:\", len(val_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_NUM = 4 # NOTE: should be 4\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Random grid search\n",
    "NUM_TRIALS = 10 # number of random searches to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1 of 2 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimekri\u001b[0m (\u001b[33minfo251-project\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\simen\\Documents\\skole\\INFO GRAD PROJ\\wandb\\run-20230501_162610-sxbcc1qp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/sxbcc1qp' target=\"_blank\">splendid-resonance-65</a></strong> to <a href='https://wandb.ai/info251-project/fgvca_aircraft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/info251-project/fgvca_aircraft' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/sxbcc1qp' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft/runs/sxbcc1qp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:30<00:00,  2.09it/s, Train loss: 4.6092, Train accuracy: 0.0060]\n",
      "100%|██████████| 63/63 [00:13<00:00,  4.63it/s, Val loss: 4.6184, Val accuracy: 0.0079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 4.6092 - Accuracy: 0.0060 - Val Loss: 4.6184 - Val Accuracy: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁</td></tr><tr><td>train loss</td><td>▁</td></tr><tr><td>val accuracy</td><td>▁</td></tr><tr><td>val loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>0.00595</td></tr><tr><td>train loss</td><td>4.60925</td></tr><tr><td>val accuracy</td><td>0.00794</td></tr><tr><td>val loss</td><td>4.61838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-resonance-65</strong> at: <a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/sxbcc1qp' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft/runs/sxbcc1qp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230501_162610-sxbcc1qp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trial 1\n",
      "Running trial 2 of 2 trials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6145374efc7943ef959832ed544f9f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\simen\\Documents\\skole\\INFO GRAD PROJ\\wandb\\run-20230501_162706-rka5ka3h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/rka5ka3h' target=\"_blank\">fresh-tree-66</a></strong> to <a href='https://wandb.ai/info251-project/fgvca_aircraft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/info251-project/fgvca_aircraft' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/rka5ka3h' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft/runs/rka5ka3h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:22<00:00,  2.80it/s, Train loss: 4.6391, Train accuracy: 0.0060]\n",
      "100%|██████████| 63/63 [00:12<00:00,  5.16it/s, Val loss: 4.6041, Val accuracy: 0.0218]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 4.6391 - Accuracy: 0.0060 - Val Loss: 4.6041 - Val Accuracy: 0.0218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15c98e4cfd64ec282832d9c817d1476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>▁</td></tr><tr><td>train loss</td><td>▁</td></tr><tr><td>val accuracy</td><td>▁</td></tr><tr><td>val loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train accuracy</td><td>0.00595</td></tr><tr><td>train loss</td><td>4.63912</td></tr><tr><td>val accuracy</td><td>0.02183</td></tr><tr><td>val loss</td><td>4.60407</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-tree-66</strong> at: <a href='https://wandb.ai/info251-project/fgvca_aircraft/runs/rka5ka3h' target=\"_blank\">https://wandb.ai/info251-project/fgvca_aircraft/runs/rka5ka3h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230501_162706-rka5ka3h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trial 2\n",
      "\n",
      " ========================= BEST PARAMETERS =========================\n",
      "{ 'trial': 2,\n",
      "  'accuracy': 0.021825396825396824,\n",
      "  'params': { 'lr': 0.1,\n",
      "              'proposal_num': 4,\n",
      "              'weight_decay': 0.0001,\n",
      "              'optimizer': 'nadam'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from torch.optim import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, NAdam\n",
    "from core.loss import list_loss, ranking_loss\n",
    "\n",
    "\n",
    "optimizers = {\n",
    "    \"sgd\": SGD,\n",
    "    \"rmsprop\": RMSprop,\n",
    "    \"adagrad\": Adagrad,\n",
    "    \"adadelta\": Adadelta,\n",
    "    \"adam\": Adam,\n",
    "    \"adamax\": Adamax,\n",
    "    \"nadam\": NAdam,\n",
    "}\n",
    "\n",
    "search_grid = {\n",
    "    \"lr\": [0.001, 0.01, 0.1],\n",
    "    \"momentum\": [0.9, 0.95],\n",
    "    \"proposal_num\": [4, 6, 8],\n",
    "    \"weight_decay\": [1e-2, 1e-4, 1e-6],\n",
    "    \"optimizer\": list(optimizers.keys()),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in range(NUM_TRIALS):\n",
    "    print(\"Running trial {} of {} trials\".format(t+1, NUM_TRIALS))\n",
    "    hr = {\n",
    "        \"lr\": np.random.choice(search_grid[\"lr\"]),\n",
    "        \"momentum\": np.random.choice(search_grid[\"momentum\"]),\n",
    "        \"proposal_num\": np.random.choice(search_grid[\"proposal_num\"]),\n",
    "        \"weight_decay\": np.random.choice(search_grid[\"weight_decay\"]),\n",
    "        \"optimizer\": np.random.choice(search_grid[\"optimizer\"]),\n",
    "    }\n",
    "\n",
    "    ################################# SETUP TRIAL #################################\n",
    "\n",
    "    optim_params = {\"lr\": hr[\"lr\"], \"weight_decay\": hr[\"weight_decay\"]}\n",
    "\n",
    "    # Add momentum\n",
    "    if hr[\"optimizer\"] in ['rmsprop', 'sgd']:\n",
    "        optim_params[\"momentum\"] = hr[\"momentum\"]\n",
    "    else:\n",
    "        del hr[\"momentum\"]\n",
    "\n",
    "    \"\"\"\n",
    "    Configure wandb\n",
    "    \"\"\"\n",
    "    wandb.init(\n",
    "        project=settings.WANDB_PROJECT_NAME,\n",
    "        config={\n",
    "            \"architecture\": \"NTS-net\",\n",
    "            \"dataset\": \"FGVCAircraft\",\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            **hr,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize dataloaders\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "    \"\"\"\n",
    "    Initialize model\n",
    "    \"\"\"\n",
    "    model = NTSModel(top_n=hr[\"proposal_num\"], cat_num=CAT_NUM, n_classes=len(dataset.classes), image_height=settings.IMAGE_HEIGHT, image_width=settings.IMAGE_WIDTH).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    \"\"\"\n",
    "    Setup optimizers\n",
    "    \"\"\"\n",
    "    resnet_parameters = list(model.resnet.parameters())\n",
    "    navigator_parameters = list(model.navigator.parameters())\n",
    "    concat_parameters = list(model.concat_net.parameters())\n",
    "    partcls_parameters = list(model.partcls_net.parameters())\n",
    "\n",
    "    resnet_optimizer = torch.optim.SGD(resnet_parameters, **optim_params)\n",
    "    navigator_optimizer = torch.optim.SGD(navigator_parameters, **optim_params)\n",
    "    concat_optimizer = torch.optim.SGD(concat_parameters, **optim_params)\n",
    "    partcls_optimizer = torch.optim.SGD(partcls_parameters, **optim_params)\n",
    "\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"val_accuracy\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        epoch_val_accuracy = 0\n",
    "        with tqdm(total=len(train_loader)) as pbar:\n",
    "            for i, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                batch_size = inputs.size(0)\n",
    "\n",
    "                resnet_optimizer.zero_grad()\n",
    "                navigator_optimizer.zero_grad()\n",
    "                concat_optimizer.zero_grad()\n",
    "                partcls_optimizer.zero_grad()\n",
    "\n",
    "                resnet_logits, concat_logits, part_logits, top_n_idxs, top_n_proba = model(inputs)\n",
    "                \n",
    "                # Losses\n",
    "                resnet_loss = criterion(resnet_logits, labels)\n",
    "                navigator_loss = list_loss(part_logits.view(batch_size * hr[\"proposal_num\"], -1),\n",
    "                                        labels.unsqueeze(1).repeat(1, hr[\"proposal_num\"]).view(-1)).view(batch_size, hr[\"proposal_num\"])\n",
    "                concat_loss = criterion(concat_logits, labels)\n",
    "                rank_loss = ranking_loss(top_n_proba, navigator_loss, proposal_num=hr[\"proposal_num\"])\n",
    "                partcls_loss = criterion(part_logits.view(batch_size * hr[\"proposal_num\"], -1),\n",
    "                                    labels.unsqueeze(1).repeat(1, hr[\"proposal_num\"]).view(-1))\n",
    "                \n",
    "                loss = resnet_loss + concat_loss + rank_loss + partcls_loss\n",
    "                loss.backward()\n",
    "\n",
    "                resnet_optimizer.step()\n",
    "                navigator_optimizer.step()\n",
    "                concat_optimizer.step()\n",
    "                partcls_optimizer.step()\n",
    "\n",
    "                accuracy = (concat_logits.argmax(dim=1) == labels).float().mean()\n",
    "                \n",
    "                epoch_loss += concat_loss.item()\n",
    "                epoch_accuracy += accuracy.item()\n",
    "\n",
    "                pbar.set_postfix_str(\"Train loss: {:.4f}, Train accuracy: {:.4f}\".format(epoch_loss / (i+1), epoch_accuracy / (i+1)))\n",
    "                pbar.update(1)\n",
    "\n",
    "\n",
    "        with tqdm(total=(len(val_loader))) as pbar:\n",
    "            with torch.no_grad():\n",
    "                for i, (inputs, labels) in enumerate(val_loader):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    batch_size = inputs.size(0)\n",
    "\n",
    "                    _, concat_logits, _, _, _ = model(inputs)\n",
    "\n",
    "                    concat_loss = criterion(concat_logits, labels)\n",
    "                    \n",
    "\n",
    "                    accuracy = (concat_logits.argmax(dim=1) == labels).float().mean()\n",
    "\n",
    "                    epoch_val_loss += concat_loss.item()\n",
    "                    epoch_val_accuracy += accuracy.item()\n",
    "\n",
    "\n",
    "                    pbar.set_postfix_str(\"Val loss: {:.4f}, Val accuracy: {:.4f}\".format(epoch_val_loss / (i+1), epoch_val_accuracy / (i+1)))\n",
    "                    pbar.update(1)\n",
    "\n",
    "        epoch_loss = epoch_loss/len(train_loader)\n",
    "        epoch_val_loss = epoch_val_loss/len(val_loader)\n",
    "\n",
    "        epoch_accuracy = epoch_accuracy/len(train_loader)\n",
    "        epoch_val_accuracy = epoch_val_accuracy/len(val_loader)\n",
    "\n",
    "        history[\"train_loss\"].append(epoch_loss)\n",
    "        history[\"val_loss\"].append(epoch_val_loss)    \n",
    "\n",
    "        history[\"train_accuracy\"].append(epoch_accuracy)\n",
    "        history[\"val_accuracy\"].append(epoch_val_accuracy) \n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_accuracy:.4f} - Val Loss: {epoch_val_loss:.4f} - Val Accuracy: {epoch_val_accuracy:.4f}\")\n",
    "    \n",
    "        # Log to wandb\n",
    "        wandb.log({\"train accuracy\": epoch_accuracy, \"train loss\": epoch_loss, \"val accuracy\": epoch_val_accuracy, \"val loss\": epoch_val_loss})\n",
    "\n",
    "\n",
    "\n",
    "    # Append trial result\n",
    "    results.append({\"trial\": t+1, \"accuracy\": history[\"val_accuracy\"][-1], \"params\": hr})\n",
    "    wandb.finish()\n",
    "    print(\"Finished trial {}\".format(t+1))\n",
    "    \n",
    "\n",
    "results = sorted(results, key=lambda x: x[\"accuracy\"], reverse=True)\n",
    "best_result = results[0]\n",
    "\n",
    "\n",
    "print(\"\\n\", \"=\"*25, \"BEST PARAMETERS\", \"=\"*25)\n",
    "pprint(best_result, sort_dicts=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
